
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Variational AutoEncoder for Anomaly Detection &#8212; Data and AI Concepts</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/generative-ai/variational_autoencoders/vae_anomaly_detection';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="The Origin" href="../../prerequisite-math/linear-algebra/introduction.html" />
    <link rel="prev" title="PCA-based Reconstruction" href="pca_for_anomaly_detection.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Data and AI Concepts - Home"/>
    <img src="../../../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Data and AI Concepts - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data and AI Concepts by @AIinMinutes
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative AI ü§ñ</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../gelu.html">GELU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../attention_mechanism.html">Scaled Dot-Product Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoencoder_latent_space.html">Ideal Properties of a Latent Space</a></li>

<li class="toctree-l1"><a class="reference internal" href="pca_for_anomaly_detection.html">Reconstruction (PCA)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Variational AutoEncoder for Anomaly Detection</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essential Math ‚ûó</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../prerequisite-math/linear-algebra/introduction.html">The Origin</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematical Statistics üé≤</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mathematical-statistics/ecdf.html">ECDF</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/AIinMinutes/Data-and-AI-Concepts.git/main?urlpath=lab/tree/book/content/generative-ai/variational_autoencoders/vae_anomaly_detection.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/generative-ai/variational_autoencoders/vae_anomaly_detection.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Variational AutoEncoder for Anomaly Detection</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#premise">Premise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-concepts-with-simple-example">Core Concepts with Simple Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation-of-the-loss-function-used-in-variational-autoencoder">Derivation of the Loss Function used in Variational AutoEncoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem">1. Bayes‚Äô Theorem:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#log-of-marginal-likelihood">2. Log of Marginal Likelihood:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-approximation-q-z-x">3. Variational Approximation (<span class="math notranslate nohighlight">\(q(z|x)\)</span>):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jensen-s-inequality-lower-bound">4. Jensen‚Äôs Inequality (Lower Bound):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplification-with-gaussian-assumptions">5. Simplification with Gaussian Assumptions:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-error-gaussian-likelihood">6. Reconstruction Error (Gaussian Likelihood):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kl-divergence">7. KL Divergence:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparameterization-trick">8. Reparameterization Trick:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-elbo-loss">9. Complete ELBO Loss:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-simplified-elbo-loss-with-beta-vae">10. Final Simplified ELBO Loss with <span class="math notranslate nohighlight">\(\beta\)</span> (Œ≤-VAE):</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="variational-autoencoder-for-anomaly-detection">
<h1><strong>Variational AutoEncoder for Anomaly Detection</strong><a class="headerlink" href="#variational-autoencoder-for-anomaly-detection" title="Link to this heading">#</a></h1>
<section id="premise">
<h2>Premise<a class="headerlink" href="#premise" title="Link to this heading">#</a></h2>
<p>The Variational Autoencoder (VAE) is a generative model that learns to encode data into a lower-dimensional latent space and then decode it back to reconstruct the original data. For anomaly detection, we exploit the fact that VAEs learn the normal data distribution, making anomalies result in higher reconstruction errors.</p>
</section>
<section id="core-concepts-with-simple-example">
<h2>Core Concepts with Simple Example<a class="headerlink" href="#core-concepts-with-simple-example" title="Link to this heading">#</a></h2>
<p>Let‚Äôs use a simple 2D point dataset to illustrate each step.</p>
<p>Example Dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Normal data: Points roughly following a circular pattern</span>
<span class="n">normal_points</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Anomaly: Point far from the pattern</span>
<span class="n">anomaly</span> <span class="o">=</span> <span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="derivation-of-the-loss-function-used-in-variational-autoencoder">
<h2>Derivation of the Loss Function used in Variational AutoEncoder<a class="headerlink" href="#derivation-of-the-loss-function-used-in-variational-autoencoder" title="Link to this heading">#</a></h2>
<section id="bayes-theorem">
<h3>1. Bayes‚Äô Theorem:<a class="headerlink" href="#bayes-theorem" title="Link to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(p(z|x) = \frac{p(x|z)p(z)}{p(x)}\)</span></p>
<p><em>Example Interpretation:</em></p>
<ul class="simple">
<li><p>x: Our 2D point (1.1, 0.8)</p></li>
<li><p>z: Lower dimensional latent representation (e.g., single number)</p></li>
<li><p>p(z|x): Probability of latent code given our point</p></li>
<li><p>p(x|z): Probability of reconstructing our point from the latent code</p></li>
<li><p>p(z): Prior beliefs about latent codes (standard normal distribution)</p></li>
<li><p>p(x): Total probability of observing the point</p></li>
</ul>
</section>
<section id="log-of-marginal-likelihood">
<h3>2. Log of Marginal Likelihood:<a class="headerlink" href="#log-of-marginal-likelihood" title="Link to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(\log p(x) = \log \int p(x|z)p(z) \, dz\)</span></p>
<p><em>Example:</em>
For our point (1.1, 0.8), we‚Äôd need to:</p>
<ol class="arabic simple">
<li><p>Consider all possible latent codes z</p></li>
<li><p>For each z, multiply:</p>
<ul class="simple">
<li><p>Probability of reconstructing (1.1, 0.8) from z</p></li>
<li><p>Probability of that z occurring</p></li>
</ul>
</li>
<li><p>Sum all these products (integral)</p></li>
<li><p>Take the log</p></li>
</ol>
</section>
<section id="variational-approximation-q-z-x">
<h3>3. Variational Approximation (<span class="math notranslate nohighlight">\(q(z|x)\)</span>):<a class="headerlink" href="#variational-approximation-q-z-x" title="Link to this heading">#</a></h3>
<p>Introduce a simpler distribution <span class="math notranslate nohighlight">\(q(z|x)\)</span> to approximate the posterior <span class="math notranslate nohighlight">\(p(z|x)\)</span>:
<span class="math notranslate nohighlight">\(\log p(x) = \log \int p(x|z)p(z) \frac{q(z|x)}{q(z|x)} \, dz\)</span></p>
<p><em>Example:</em>
Instead of computing exact probabilities, we use a neural network (encoder) to predict:</p>
<ul class="simple">
<li><p>Mean (Œº) and variance (œÉ¬≤) of a Gaussian distribution for our point (1.1, 0.8)</p></li>
<li><p>e.g., Œº = 0.5, œÉ¬≤ = 0.1</p></li>
</ul>
</section>
<section id="jensen-s-inequality-lower-bound">
<h3>4. Jensen‚Äôs Inequality (Lower Bound):<a class="headerlink" href="#jensen-s-inequality-lower-bound" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\log p(x) &amp;= \log \mathbb{E}_{q(z|x)}\left[\frac{p(x|z)p(z)}{q(z|x)}\right] \\
&amp;\geq \int q(z|x) \log \frac{p(x|z)p(z)}{q(z|x)} \, dz \\
&amp;= \mathbb{E}_{q(z|x)} [ \log p(x|z) + \log p(z) - \log q(z|x) ]
\end{aligned}\end{split}\]</div>
<p><em>Example:</em>
For our point, this means:</p>
<ol class="arabic simple">
<li><p>Sample latent codes from our predicted distribution (Œº = 0.5, œÉ¬≤ = 0.1)</p></li>
<li><p>For each sample:</p>
<ul class="simple">
<li><p>Reconstruct the point</p></li>
<li><p>Calculate reconstruction probability</p></li>
<li><p>Add prior probability</p></li>
<li><p>Subtract encoding probability</p></li>
</ul>
</li>
<li><p>Average these values</p></li>
</ol>
</section>
<section id="simplification-with-gaussian-assumptions">
<h3>5. Simplification with Gaussian Assumptions:<a class="headerlink" href="#simplification-with-gaussian-assumptions" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Prior</strong>: <span class="math notranslate nohighlight">\( p(z) = \mathcal{N}(z; 0, I) \)</span></p></li>
<li><p><strong>Variational Posterior</strong>: <span class="math notranslate nohighlight">\( q(z|x) = \mathcal{N}(z; \mu_q(x), \text{diag}(\sigma_q^2(x))) \)</span></p></li>
<li><p><strong>Likelihood</strong>: <span class="math notranslate nohighlight">\( p(x|z) = \mathcal{N}(x; f(z), \sigma^2I) \)</span></p></li>
</ul>
<p><em>Example:</em>
For (1.1, 0.8):</p>
<ul class="simple">
<li><p>Prior: Assume latent codes follow standard normal</p></li>
<li><p>Encoder predicts: Œº = 0.5, œÉ¬≤ = 0.1</p></li>
<li><p>Decoder predicts: reconstruction = (1.0, 0.9)</p></li>
</ul>
</section>
<section id="reconstruction-error-gaussian-likelihood">
<h3>6. Reconstruction Error (Gaussian Likelihood):<a class="headerlink" href="#reconstruction-error-gaussian-likelihood" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{q(z|x)} [ \log p(x|z) ] = \mathbb{E}_{q(z|x)}\left[-\frac{1}{2\sigma^2}\|x - f(z)\|^2 - \frac{n}{2}\log(2\pi\sigma^2)\right]\]</div>
<p><em>Example:</em></p>
<ul class="simple">
<li><p>Original point: (1.1, 0.8)</p></li>
<li><p>Reconstructed point: (1.0, 0.9)</p></li>
<li><p>Error = ‚àö((1.1-1.0)¬≤ + (0.8-0.9)¬≤) = 0.141</p></li>
</ul>
</section>
<section id="kl-divergence">
<h3>7. KL Divergence:<a class="headerlink" href="#kl-divergence" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[D_{KL}(q(z|x) \| p(z)) = \frac{1}{2}\sum_{i=1}^{d} (\sigma_{q,i}^2 + \mu_{q,i}^2 - \log \sigma_{q,i}^2 - 1)\]</div>
<p><em>Example:</em>
For our predicted distribution (Œº = 0.5, œÉ¬≤ = 0.1):
KL = 0.5 * (0.1 + 0.5¬≤ - log(0.1) - 1) = 1.35</p>
</section>
<section id="reparameterization-trick">
<h3>8. Reparameterization Trick:<a class="headerlink" href="#reparameterization-trick" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[z = \mu_q(x) + \sigma_q(x) \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)\]</div>
<p><em>Example:</em>
Instead of sampling directly from N(0.5, 0.1):</p>
<ol class="arabic simple">
<li><p>Sample Œµ ~ N(0, 1), e.g., Œµ = 0.3</p></li>
<li><p>Compute: z = 0.5 + ‚àö0.1 * 0.3 = 0.595</p></li>
</ol>
</section>
<section id="complete-elbo-loss">
<h3>9. Complete ELBO Loss:<a class="headerlink" href="#complete-elbo-loss" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\text{ELBO} &amp;= \mathbb{E}_{\epsilon \sim \mathcal{N}(0, I)}\left[-\frac{1}{2\sigma^2}\|x - f(\mu_q(x) + \sigma_q(x) \odot \epsilon)\|^2\right] \\
&amp;- \frac{1}{2}\sum_{i=1}^{d} (\sigma_{q,i}^2 + \mu_{q,i}^2 - \log \sigma_{q,i}^2 - 1) - \frac{n}{2}\log(2\pi\sigma^2)
\end{aligned}\end{split}\]</div>
<p><em>Example:</em>
Combining:</p>
<ul class="simple">
<li><p>Reconstruction error: 0.141</p></li>
<li><p>KL divergence: 1.35
ELBO ‚âà -0.141 - 1.35 = -1.491</p></li>
</ul>
</section>
<section id="final-simplified-elbo-loss-with-beta-vae">
<h3>10. Final Simplified ELBO Loss with <span class="math notranslate nohighlight">\(\beta\)</span> (Œ≤-VAE):<a class="headerlink" href="#final-simplified-elbo-loss-with-beta-vae" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{\beta\text{-VAE}} = \mathbb{E}_{\epsilon \sim \mathcal{N}(0, I)}\left[-\frac{1}{2\sigma^2}\|x - f(\mu_q(x) + \sigma_q(x) \odot \epsilon)\|^2\right] - \beta D_{KL}(q(z|x)\|p(z))\]</div>
<p><em>Example with Œ≤ = 0.5:</em>
$<span class="math notranslate nohighlight">\(\mathcal{L}_{\beta\text{-VAE}} = -0.141 - 0.5 * 1.35 = -0.816\)</span>$</p>
<p>For anomaly detection:</p>
<ul class="simple">
<li><p>Normal point (1.1, 0.8): Loss = -0.816</p></li>
<li><p>Anomaly point (4.0, 4.0): Loss ‚âà -5.234 (much higher reconstruction error)</p></li>
</ul>
<p>This higher loss for the anomaly point indicates it doesn‚Äôt fit the learned normal data distribution, allowing us to detect it as an anomaly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span><span class="nv">pyod</span><span class="o">==</span><span class="m">2</span>.0.2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyod.models.vae</span><span class="w"> </span><span class="kn">import</span> <span class="n">VAE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyod.models.auto_encoder</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyod.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">generate_data</span><span class="p">,</span> <span class="n">evaluate_print</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">balanced_accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;dark_background&#39;</span><span class="p">)</span>

<span class="c1"># Generate synthetic data</span>
<span class="n">contamination</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span>
    <span class="n">n_train</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span> 
    <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
    <span class="n">contamination</span><span class="o">=</span><span class="n">contamination</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Train the VAE model</span>
<span class="n">clf_name_vae</span> <span class="o">=</span> <span class="s1">&#39;VAE&#39;</span>
<span class="n">vae_clf</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">epoch_num</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> 
              <span class="n">contamination</span><span class="o">=</span><span class="n">contamination</span><span class="p">,</span> 
              <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">vae_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:   0%|                                      | 0/30 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:   3%|‚ñà                             | 1/30 [00:00&lt;00:07,  3.78it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  10%|‚ñà‚ñà‚ñà                           | 3/30 [00:00&lt;00:03,  8.81it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  17%|‚ñà‚ñà‚ñà‚ñà‚ñà                         | 5/30 [00:00&lt;00:02, 11.74it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 7/30 [00:00&lt;00:01, 13.27it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 9/30 [00:00&lt;00:01, 13.86it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 11/30 [00:00&lt;00:01, 14.72it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 13/30 [00:00&lt;00:01, 15.53it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 15/30 [00:01&lt;00:00, 16.19it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 17/30 [00:01&lt;00:00, 16.62it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 19/30 [00:01&lt;00:00, 16.77it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 21/30 [00:01&lt;00:00, 16.64it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 23/30 [00:01&lt;00:00, 16.93it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 25/30 [00:01&lt;00:00, 17.20it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 27/30 [00:01&lt;00:00, 16.89it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 29/30 [00:01&lt;00:00, 16.87it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:01&lt;00:00, 15.09it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the AE model</span>
<span class="n">clf_name_ae</span> <span class="o">=</span> <span class="s1">&#39;AE&#39;</span>
<span class="n">ae_clf</span> <span class="o">=</span> <span class="n">AutoEncoder</span><span class="p">(</span><span class="n">epoch_num</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> 
                     <span class="n">contamination</span><span class="o">=</span><span class="n">contamination</span><span class="p">)</span>
<span class="n">ae_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Predictions and scores for VAE</span>
<span class="n">y_test_pred_vae</span> <span class="o">=</span> <span class="n">vae_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Predictions and scores for AE</span>
<span class="n">y_test_pred_ae</span> <span class="o">=</span> <span class="n">ae_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">balanced_accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="p">)</span>

<span class="c1"># Compute metrics function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">balanced_acc</span> <span class="o">=</span> <span class="n">balanced_accuracy_score</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span>
    <span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">balanced_acc</span><span class="p">,</span> <span class="n">f1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:   0%|                                      | 0/30 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:   7%|‚ñà‚ñà                            | 2/30 [00:00&lt;00:01, 17.13it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  13%|‚ñà‚ñà‚ñà‚ñà                          | 4/30 [00:00&lt;00:01, 17.68it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 6/30 [00:00&lt;00:01, 18.47it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 8/30 [00:00&lt;00:01, 18.99it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 10/30 [00:00&lt;00:01, 18.63it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 12/30 [00:00&lt;00:01, 17.92it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 14/30 [00:00&lt;00:00, 17.92it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 16/30 [00:00&lt;00:00, 18.41it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 19/30 [00:01&lt;00:00, 18.97it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 22/30 [00:01&lt;00:00, 20.52it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 25/30 [00:01&lt;00:00, 20.68it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/30 [00:01&lt;00:00, 21.70it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:01&lt;00:00, 19.98it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">visualize_detailed_results</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="c1"># Compute metrics</span>
    <span class="n">balanced_acc</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Plot points with different categories</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> 
               <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Positive (Anomaly)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> 
               <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Negative (Non-Anomaly)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> 
               <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;False Positive (Non-Anomaly)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> 
               <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;False Negative (Anomaly)&#39;</span><span class="p">)</span>
    
    <span class="c1"># Title with metrics</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="se">\n</span><span class="s2">Balanced Acc: </span><span class="si">{</span><span class="n">balanced_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, F1: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 2&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="c1"># Create subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1"># Visualize results for VAE on test data</span>
<span class="n">visualize_detailed_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred_vae</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">,</span> <span class="s2">&quot;Test Data&quot;</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># Visualize results for AE on test data</span>
<span class="n">visualize_detailed_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred_ae</span><span class="p">,</span> <span class="s2">&quot;AE&quot;</span><span class="p">,</span> <span class="s2">&quot;Test Data&quot;</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Visualize results for VAE on training data</span>
<span class="n">visualize_detailed_results</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">vae_clf</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">,</span> <span class="s2">&quot;Training Data&quot;</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># Visualize results for AE on training data</span>
<span class="n">visualize_detailed_results</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">ae_clf</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="s2">&quot;AE&quot;</span><span class="p">,</span> <span class="s2">&quot;Training Data&quot;</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/86ce4a3b87801a76cc7d1f9a76e06102de59a6e4d984c58a66effa1e9885cb93.png" src="../../../_images/86ce4a3b87801a76cc7d1f9a76e06102de59a6e4d984c58a66effa1e9885cb93.png" />
</div>
</div>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Aspect</strong></p></th>
<th class="head"><p><strong>Autoencoder (AE)</strong></p></th>
<th class="head"><p><strong>Variational Autoencoder (VAE)</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Latent Space</strong></p></td>
<td><p>Deterministic representation (fixed point for each input)</p></td>
<td><p>Probabilistic representation (distribution over latent variables)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Latent Space Structure</strong></p></td>
<td><p>No specific regularization; can be scattered and unstructured</p></td>
<td><p>Regularized to match a predefined prior (typically Gaussian), resulting in a smooth, continuous space</p></td>
</tr>
<tr class="row-even"><td><p><strong>Objective</strong></p></td>
<td><p>Minimize reconstruction error (e.g., MSE)</p></td>
<td><p>Minimize both reconstruction error and KL divergence to enforce latent space structure</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Encoder Output</strong></p></td>
<td><p>Direct mapping to a single point in latent space</p></td>
<td><p>Outputs parameters of a distribution (mean and variance) for each latent variable</p></td>
</tr>
<tr class="row-even"><td><p><strong>Generative Capability</strong></p></td>
<td><p>Limited generative ability; may not generalize well for new data</p></td>
<td><p>Strong generative capability due to regularized latent space</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Latent Variable Interpolation</strong></p></td>
<td><p>Less smooth interpolation between latent variables</p></td>
<td><p>Smooth interpolation due to the continuous nature of the latent space</p></td>
</tr>
<tr class="row-even"><td><p><strong>KL Divergence</strong></p></td>
<td><p>Not used in the loss function</p></td>
<td><p>KL divergence term in the loss function regularizes the latent space</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Reconstruction</strong></p></td>
<td><p>Reconstructs the input deterministically</p></td>
<td><p>Reconstructs the input probabilistically, sampling from the learned latent distribution</p></td>
</tr>
<tr class="row-even"><td><p><strong>Use Cases</strong></p></td>
<td><p>Mainly used for dimensionality reduction and reconstruction tasks</p></td>
<td><p>Used for generative modeling, data generation, and anomaly detection</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Regularization</strong></p></td>
<td><p>None</p></td>
<td><p>Explicit regularization to ensure the latent space follows a known distribution (e.g., Gaussian)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "book"
        },
        kernelOptions: {
            name: "book",
            path: "./content/generative-ai/variational_autoencoders"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'book'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pca_for_anomaly_detection.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>PCA-based Reconstruction</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="../../prerequisite-math/linear-algebra/introduction.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Origin</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#premise">Premise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-concepts-with-simple-example">Core Concepts with Simple Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation-of-the-loss-function-used-in-variational-autoencoder">Derivation of the Loss Function used in Variational AutoEncoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem">1. Bayes‚Äô Theorem:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#log-of-marginal-likelihood">2. Log of Marginal Likelihood:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-approximation-q-z-x">3. Variational Approximation (<span class="math notranslate nohighlight">\(q(z|x)\)</span>):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jensen-s-inequality-lower-bound">4. Jensen‚Äôs Inequality (Lower Bound):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplification-with-gaussian-assumptions">5. Simplification with Gaussian Assumptions:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-error-gaussian-likelihood">6. Reconstruction Error (Gaussian Likelihood):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kl-divergence">7. KL Divergence:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparameterization-trick">8. Reparameterization Trick:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-elbo-loss">9. Complete ELBO Loss:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-simplified-elbo-loss-with-beta-vae">10. Final Simplified ELBO Loss with <span class="math notranslate nohighlight">\(\beta\)</span> (Œ≤-VAE):</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By ‚ù§Ô∏èAIinMinutes
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>