
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Full Stack Data Science Potential Interview Questios üìö &#8212; Data and AI Concepts</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/IQs';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Gaussian Mixture Models" href="generative-ai/matrix-calculus-for-genAI/gaussian_mixture_models.html" />
    <link rel="prev" title="Data and AI Concepts by @AIinMinutes" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Data and AI Concepts - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Data and AI Concepts - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Potential Interview Questions</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">For Full Stack Data Scientists</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative AI ü§ñ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/gaussian_mixture_models.html">Gaussian Mixture Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/large-language-modelling/causal_attention.html">Causal Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/large-language-modelling/decoding_strategies.html">Text Decoding Strategies--Greedy vs Beam</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/large-language-modelling/layer_and_rms_normalization.html">Layer vs RMS Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/large-language-modelling/multi_head_attention.html">Multi-head Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/variational_autoencoders/autoencoder_latent_space.html">Ideal Properties of a Latent Space</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/variational_autoencoders/pca_for_anomaly_detection.html">PCA for Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/variational_autoencoders/vae_anomaly_detection.html">Variational AutoEncoder for Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/variational_autoencoders/vae_on_mnist.html">Variational AutoEncoder Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/attention_mechanism.html">Attention Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/gelu.html">GELU</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/orthogonality.html">Orthogonality</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/perplexity.html">Perplexity</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning üß†</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="deep-learning/focal_loss_balanced.html">Balanced Focal Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-learning/jensen_inequality.html">Jensen's Inequality</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-learning/reparametrization_trick.html">Reparametrization Trick</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-learning/temperature_scaled_softmax.html">Temperature Scaled Softmax</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Interpretable AI üîç</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="interpretable-ai/logistic_regression.html">Logistic Regression Coefficient Interpretation</a></li>
<li class="toctree-l1"><a class="reference internal" href="interpretable-ai/shapley.html">Shapley values and SHAP for ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="interpretable-ai/model_counterfactuals.html">Counterfactuals</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning üîß</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="machine-learning/trees-and-forests/gini_impurity_vs_entropy.html">Gini Impurity vs Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/agglomerative_clustering.html">Agglomerative Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/elastic_net.html">Elastic Net</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/huber_loss.html">Huber Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/mahalanobis_distance.html">Mahalanobis Distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/natural_breaks.html">Natural Breaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/oversampling.html">Oversampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/pca_vs_feat_ag.html">PCA vs Feature Agglomeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/permutation_importance.html">Permutation Importance</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-learning/pseudo_r2.html">Pseudo R¬≤</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematical Statistics üé≤</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/chebyshev_inequality.html">Chebyshev's Inequality</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/dist_of_minimum.html">Distribution of Minimum</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/matrix_calculus_short.html">Matrix Calculus Jacobians and Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/multivariate_normal_distribution.html">Multivariate Normal Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/mutual_information.html">Mutual Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/point_biserial.html">Point Biserial Correlation Coefficient</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/unbiased_vs_consistent.html">Unbiasesd vs Consistent Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathematical-statistics/ecdf.html">ECDF</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Applied Statistics üìä</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/acf_and_pacf.html">Autocorrelation Function vs Partial Autocorrelation Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/adjusted_r_squared.html">Adjusted R¬≤</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/condition_number.html">Condition Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/cramer_v.html">Cramer's V</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/ewa_and_bias_correction.html">Exponentially Weighted Average and Bias Correction</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/kruskal_wallis.html">Kruskal Wallis</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/kendalltaub.html">Kendall's Rank Correlation Coefficient</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/spurious_correlation.html">Spurious Correlation</a></li>
<li class="toctree-l1"><a class="reference internal" href="applied-statistics/predictive_r2.html">Leave One Out Cross Validation and PRESS</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multivariate Statistics üìà</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="multivariate-statistics/canonical_correlation_analysis.html">Canonical Correlation Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="multivariate-statistics/correspondence_analysis.html">Correspondence Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="multivariate-statistics/factor_analysis.html">Factor Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="multivariate-statistics/hotelling.html">Hotelling's T¬≤</a></li>
<li class="toctree-l1"><a class="reference internal" href="multivariate-statistics/principal_component_analysis.html">Principal Component Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisite Mathematics ‚ûó</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="prerequisite-math/linear-algebra/introduction.html">The Origin</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/energy.html">Energy</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/hyperplanes.html">Hyperplanes</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/inner_product.html"><strong>Inner Product</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/moore_penrose_inverse.html">Moore Penrose Inverse</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/multiclass_classification.html">Jacobians and Gradients behind Multi-class Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/norm_and_metric.html">Norm and Metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative-ai/matrix-calculus-for-genAI/rank_one_matrices.html"><strong>Rank-1 Matrices</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="prerequisite-math/linear-algebra/spectral_decomposition.html">Spectral Decomposition</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Programming üíª</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="programming/leetcode-python/kadanes.html">Kadane's Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming/leetcode-python/prefix_sum.html">Prefix Sum and Sliding Window</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming/leetcode-python/two_pointer.html">Two Pointer</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming/pandas/pivoting.html">Pivoting in Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming/optimization/cudf.html">Pandas on NVIDIA GPUs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/AIinMinutes/Data-and-AI-Concepts" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AIinMinutes/Data-and-AI-Concepts/issues/new?title=Issue%20on%20page%20%2Fcontent/IQs.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/content/IQs.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Full Stack Data Science Potential Interview Questios üìö</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics"><strong>Statistics++</strong> üìä</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra-matrix-operations"><strong>Linear Algebra &amp; Matrix Operations</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-theory-methods"><strong>Statistical Theory &amp; Methods</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-inference-testing"><strong>Statistical Inference &amp; Testing</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-intelligence"><strong>Artificial Intelligence</strong> ü§ñ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-fundamentals"><strong>Deep Learning Fundamentals</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-processing-llms"><strong>Natural Language Processing &amp; LLMs</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-methods"><strong>Machine Learning Methods</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#engineering-implementation"><strong>Engineering &amp; Implementation</strong> üõ†</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-engineering-processing"><strong>Data Engineering &amp; Processing</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering-selection"><strong>Feature Engineering &amp; Selection</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production-monitoring"><strong>Production &amp; Monitoring</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="full-stack-data-science-potential-interview-questios">
<h1><strong>Full Stack Data Science Potential Interview Questios</strong> üìö<a class="headerlink" href="#full-stack-data-science-potential-interview-questios" title="Link to this heading">#</a></h1>
<section id="statistics">
<h2><strong>Statistics++</strong> üìä<a class="headerlink" href="#statistics" title="Link to this heading">#</a></h2>
<section id="linear-algebra-matrix-operations">
<h3><strong>Linear Algebra &amp; Matrix Operations</strong><a class="headerlink" href="#linear-algebra-matrix-operations" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>How do you calculate mean squared error in a vectorized way?</p></li>
<li><p>Why can eigenvalue decomposition only be performed on square matrices?</p></li>
<li><p>Why can eigenvalues of a projection (hat) matrix only be 0 or 1?</p></li>
<li><p>What are the applications of Singular Value Decomposition (SVD) in Machine Learning?</p></li>
<li><p>What is the Moore-Penrose inverse, &amp; how is it related to least squares?</p></li>
<li><p>Why do we perform eigenvalue decomposition of the sample covariance matrix to identify principal components?</p></li>
<li><p>Why is the determinant of an orthogonal matrix <span class="math notranslate nohighlight">\(Q\)</span> either 1 or -1?</p></li>
<li><p>If you apply a dropout layer with a drop rate of 0.5 to a matrix of ones, you will see that some elements of the output matrix become zero, while the remaining elements are set to 2. Why?</p></li>
<li><p>There are two random variables, <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, and the covariance between them is 0.5. Also, the variances are: <span class="math notranslate nohighlight">\(Var(X) = 2\)</span> and <span class="math notranslate nohighlight">\(Var(Y) = 1\)</span>. Two new random variables, <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(Q\)</span>, are defined as follows: <span class="math notranslate nohighlight">\(P = 2X + 4Y\)</span>, <span class="math notranslate nohighlight">\(Q = 4X - 2Y\)</span>. So, what‚Äôs the covariance between <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(Q\)</span>?</p></li>
<li><p>What is cosine distance? Is it a distance metric?</p></li>
<li><p>How do you calculate the distance between two parallel hyperplanes?</p></li>
<li><p>How do quadratic forms (energy) relate to a matrix‚Äôs definiteness, and what does this reveal about its behavior?</p></li>
<li><p>What does the norm of a vector represent?</p></li>
<li><p>What does the inner product of two vectors represent, and how is it related to the kernel trick?</p></li>
<li><p>What is Singular Value Decomposition? How is it related to rank one matrices?</p></li>
<li><p>Do all orthogonal matrices perform rotational transformation preserving norm and orientation?</p></li>
<li><p>Are factor loadings in an orthogonal factor analysis model unique, or do they change with different rotations?</p></li>
<li><p>If <span class="math notranslate nohighlight">\(A\)</span> is a matrix of any shape with all real elements, how are its singular values related to the eigenvalues of <span class="math notranslate nohighlight">\(A^TA\)</span>?</p></li>
<li><p>Let‚Äôs say there is a function <span class="math notranslate nohighlight">\(f(x) = x^TAx\)</span> where <span class="math notranslate nohighlight">\(x\)</span> is a column vector of size <span class="math notranslate nohighlight">\(n \times 1\)</span> and <span class="math notranslate nohighlight">\(A\)</span> is a <span class="math notranslate nohighlight">\((n \times n)\)</span> square matrix. What is the gradient of <span class="math notranslate nohighlight">\(f(x)\)</span> with respect to <span class="math notranslate nohighlight">\(x\)</span>?</p></li>
</ol>
</section>
<section id="statistical-theory-methods">
<h3><strong>Statistical Theory &amp; Methods</strong><a class="headerlink" href="#statistical-theory-methods" title="Link to this heading">#</a></h3>
<ol class="arabic">
<li><p>If <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> are two normally distributed random variables that jointly follow a bivariate normal distribution, why does the lack of correlation between them imply that they are independent, even though, in general, zero correlation does not imply independence?</p></li>
<li><p>Why do we divide the sum of squares by <span class="math notranslate nohighlight">\((n - 1)\)</span> instead of <span class="math notranslate nohighlight">\(n\)</span> (where <span class="math notranslate nohighlight">\(n\)</span> is the sample size) when calculating sample variance?</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> are two independent random variables following chi-square distribution with <span class="math notranslate nohighlight">\(n_1\)</span> and <span class="math notranslate nohighlight">\(n_2\)</span> degrees of freedom, respectively. What distribution does <span class="math notranslate nohighlight">\(X_1 + X_2\)</span> follow?</p></li>
<li><p>What is a log-normal distribution? Why is a random variable following a log-normal distribution always greater than zero?</p></li>
<li><p>What is the standard error of mean (SEM)?</p></li>
<li><p>A population is normally distributed, and we want to test if the population mean (<span class="math notranslate nohighlight">\(\mu\)</span>) is equal to <span class="math notranslate nohighlight">\(\mu_0\)</span>. The population standard deviation is unknown. We compute the following test statistic, <span class="math notranslate nohighlight">\(T\)</span>, based on a random sample of <span class="math notranslate nohighlight">\(n\)</span> independent observations drawn from the population:</p>
<p><span class="math notranslate nohighlight">\(
T = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}
\)</span></p>
<p>where: <span class="math notranslate nohighlight">\(\bar{X}\)</span> is the sample mean, <span class="math notranslate nohighlight">\(S\)</span> is the sample standard deviation, <span class="math notranslate nohighlight">\(n\)</span> is the sample size. What probability distribution does <span class="math notranslate nohighlight">\(T\)</span> follow?</p>
</li>
<li><p>The outcome of four coin tosses is [1, 1, 1, 0], where 1 represents getting heads and 0 represents getting tails. Using Maximum Likelihood Estimation (MLE), what is the estimated probability of getting head in a single coin toss?</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span> be three random variables. If <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent, does this imply that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are conditionally independent given <span class="math notranslate nohighlight">\(Z\)</span>?</p></li>
<li><p>What is Chebyshev‚Äôs Inequality?</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> follows a distribution function <span class="math notranslate nohighlight">\(F_X(x)\)</span>, and you collect a sample of size <span class="math notranslate nohighlight">\(n\)</span> (IID), what distribution does the minimum of the sample follow?</p></li>
<li><p>What is the difference between the unbiasedness and the consistency of an estimator?</p></li>
<li><p>What is Jensen‚Äôs Inequality?</p></li>
</ol>
</section>
<section id="statistical-inference-testing">
<h3><strong>Statistical Inference &amp; Testing</strong><a class="headerlink" href="#statistical-inference-testing" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is the coefficient of determination (<span class="math notranslate nohighlight">\(R^2\)</span>)? Why is it not always a good evaluation metric in multiple linear regression? Alternative?</p></li>
<li><p>Pearson‚Äôs correlation is used to estimate the strength and the direction of the linear relationship between two continuous variables. What metric is used to judge the association between two categorical variables?</p></li>
<li><p>Let‚Äôs say there are three variables <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>. You are interested in estimating the strength of the linear relationship between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> while controlling for <span class="math notranslate nohighlight">\(Z\)</span>. Which correlation coefficient would you calculate?</p></li>
<li><p>How are <span class="math notranslate nohighlight">\(R^2\)</span> and adjusted <span class="math notranslate nohighlight">\(R^2\)</span> different?</p></li>
<li><p>What is the issue of multiple testing?</p></li>
<li><p>Comparing the means of two groups is common to assess the effect of a treatment. One assumption of the independent t-test is that the variances of the two groups must be equal. Which test can you use to check if the variances of the groups are equal? If they are found to be unequal, which test would you use to compare the means?</p></li>
<li><p>How would you evaluate the association between job roles and preferred movie genre using the provided data?</p></li>
<li><p>Normality is one of the key assumptions of one-way ANOVA. If it is violated, which non-parametric test is generally used?</p></li>
<li><p>How do you test for spurious correlation between two variables controlling for a third variable?</p></li>
<li><p>A company surveys 20 data scientists to evaluate the association between job satisfaction and work-life balance, both rated from 1 to 5. Is there an association between the two? Sample: <span class="math notranslate nohighlight">\(s = [(5, 4), (3, 3), ..., (3, 3)]\)</span></p></li>
</ol>
</section>
</section>
<section id="artificial-intelligence">
<h2><strong>Artificial Intelligence</strong> ü§ñ<a class="headerlink" href="#artificial-intelligence" title="Link to this heading">#</a></h2>
<section id="deep-learning-fundamentals">
<h3><strong>Deep Learning Fundamentals</strong><a class="headerlink" href="#deep-learning-fundamentals" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is ‚ÄúWeight Sharing‚Äù in the context of neural networks? What are its benefits?</p></li>
<li><p>If a convolutional layer takes an input image with 10 channels and applies a convolution operation to produce 32 output channels using a <span class="math notranslate nohighlight">\(7\times7\)</span> square kernel, how many total learnable parameters (including bias) are there?</p></li>
<li><p>What is Layer Normalization used for?</p></li>
<li><p>How does RMS Normalization differ from Layer Normalization?</p></li>
<li><p>What is the difference between the Gaussian Error Linear Unit (GELU) and the Rectified Linear Unit (ReLU) as activation functions?</p></li>
<li><p>How is AutoEncoder used for Dimensionality Reduction (onto Latent Space)?</p></li>
<li><p>What is the loss function used in Variational AutoEncoders?</p></li>
<li><p>How is a Variational Autoencoder (VAE) trained, and how does its latent space differ from that of an Autoencoder (AE)?</p></li>
<li><p>In deep learning, we generally use equal-sized batches during training. Why is this the case?</p></li>
</ol>
</section>
<section id="natural-language-processing-llms">
<h3><strong>Natural Language Processing &amp; LLMs</strong><a class="headerlink" href="#natural-language-processing-llms" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is the difference between Lemmatization and Stemming?</p></li>
<li><p>What is Nucleus sampling? How is it used to control the text-generation process by LLMs?</p></li>
<li><p>How would you explain to a layman the contextualized embedding of a word in a sentence that a transformer model learns?</p></li>
<li><p>What is the attention mechanism?</p></li>
<li><p>How are knowledge graphs used to improve factual accuracy of LLMs?</p></li>
<li><p>Why is causal attention used in autoregressive language models such as GPT?</p></li>
<li><p>How does using multiple attention heads improve the performance of transformers?</p></li>
<li><p>Does the perplexity of predictions decrease or increase with increasing context size?</p></li>
<li><p>How is the greedy search decoding strategy different from the beam search decoding strategy?</p></li>
<li><p>How does temperature scaling influence the diversity of responses generated by a large language model (LLM)?</p></li>
</ol>
</section>
<section id="machine-learning-methods">
<h3><strong>Machine Learning Methods</strong><a class="headerlink" href="#machine-learning-methods" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is cosine similarity? What does it measure? How is it different from Euclidean distance? In what scenarios is it a better measure for comparison than Euclidean distance?</p></li>
<li><p>What is Minkowski distance? What are its applications in machine learning?</p></li>
<li><p>What are threshold-dependent metrics used to evaluate the performance of a binary classifier?</p></li>
<li><p>What‚Äôs a simple metric to evaluate a time-series forecasting model?</p></li>
<li><p>What metric serves as the equivalent of <span class="math notranslate nohighlight">\(R^2\)</span> (coefficient of determination) in a logistic regression model?</p></li>
<li><p>Though multicollinearity doesn‚Äôt affect the predictive performance of a model, you may still want to address it even if model interpretability is not your goal. Why?</p></li>
<li><p>Why is L1 regularization (LASSO) used for automated feature selection in linear models?</p></li>
<li><p>In a logistic regression model, what is the interpretation of the coefficient of a predictor (assuming it is not part of any interaction term)? What does this coefficient represent?</p></li>
<li><p>How do shrinkage methods address multi-collinearity in linear regression?</p></li>
<li><p>Why does Gini impurity favor the majority class in classification compared to entropy?</p></li>
</ol>
</section>
</section>
<section id="engineering-implementation">
<h2><strong>Engineering &amp; Implementation</strong> üõ†<a class="headerlink" href="#engineering-implementation" title="Link to this heading">#</a></h2>
<section id="data-engineering-processing">
<h3><strong>Data Engineering &amp; Processing</strong><a class="headerlink" href="#data-engineering-processing" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is the difference between row-oriented and column-oriented data?</p></li>
<li><p>Labelers A and B have classified a set of 20 images as either ‚Äúcat‚Äù or ‚Äúdog.‚Äù Which metric would you use to evaluate the level of concordance between their labels?</p></li>
<li><p>How can you transform a long-format DataFrame into a wide-format DataFrame in pandas?</p></li>
<li><p>What is training-serving skew?</p></li>
<li><p>What are the different types of anomalies that can occur in a time-series (multi-channel) dataset?</p></li>
<li><p>What is the difference between cross-entropy loss and sparse cross-entropy loss?</p></li>
<li><p>You have two models trained for multi-class classification, where one class in your dataset is a minority (approximately 5%). Two popular averaging methods, micro and macro, are used to generalize binary evaluation metrics such as precision and recall. What are the differences between the two methods? For the given problem, which method would you choose?</p></li>
</ol>
</section>
<section id="feature-engineering-selection">
<h3><strong>Feature Engineering &amp; Selection</strong><a class="headerlink" href="#feature-engineering-selection" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>What is the difference between standardization and normalization?</p></li>
<li><p>How can you address class imbalance in a dataset by synthetically generating new samples for the minority class, ensuring the new samples are similar to the original data distribution but not identical duplicates?</p></li>
<li><p>How does the balanced focal loss function address both class imbalance and the challenge of hard-to-classify instances in machine learning models?</p></li>
<li><p>Why is Mutual Information score a better criterion for feature selection than rank and linear correlation coefficients?</p></li>
<li><p>How is Principal Component Analysis used for Multivariate Anomaly Detection?</p></li>
<li><p>How does condition number and variance inflation factor help detecting multicollinearity?</p></li>
<li><p>Any model-agnostic way to estimate feature importance?</p></li>
</ol>
</section>
<section id="production-monitoring">
<h3><strong>Production &amp; Monitoring</strong><a class="headerlink" href="#production-monitoring" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Maintaining an ML model in production can be complicated. You may need to retrain the model, update thresholds, or continuously train the model as new data comes in. The approach you choose largely depends on the type of drift that has occurred. In this context, how are covariate drift and concept drift different?</p></li>
<li><p>What is a generative model? How is it different from a classification model?</p></li>
<li><p>How do you solve an over(under)-determined system of linear equations?</p></li>
<li><p>What is Huber Loss, and why is it preferred over Mean Squared Error (MSE) in the presence of outliers?</p></li>
<li><p>How does the Jacobian come into play when calculating the gradient of a scalar loss function with matrix parameters?</p></li>
<li><p>What is the log-sum-exp trick?</p></li>
<li><p>What is weakly stationary time series?</p></li>
<li><p>What is Granger Causality?</p></li>
<li><p>How are Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) different?</p></li>
<li><p>What is exponentially weighted average (EWA)? How is it used for time-series forecasting?</p></li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Data and AI Concepts by &#64;AIinMinutes</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="generative-ai/matrix-calculus-for-genAI/gaussian_mixture_models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Gaussian Mixture Models</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics"><strong>Statistics++</strong> üìä</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra-matrix-operations"><strong>Linear Algebra &amp; Matrix Operations</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-theory-methods"><strong>Statistical Theory &amp; Methods</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-inference-testing"><strong>Statistical Inference &amp; Testing</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-intelligence"><strong>Artificial Intelligence</strong> ü§ñ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-fundamentals"><strong>Deep Learning Fundamentals</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-processing-llms"><strong>Natural Language Processing &amp; LLMs</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-methods"><strong>Machine Learning Methods</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#engineering-implementation"><strong>Engineering &amp; Implementation</strong> üõ†</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-engineering-processing"><strong>Data Engineering &amp; Processing</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering-selection"><strong>Feature Engineering &amp; Selection</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production-monitoring"><strong>Production &amp; Monitoring</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By @AIinMinutes
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>