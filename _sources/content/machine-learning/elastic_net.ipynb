{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf2d4309-9e84-40c3-a5df-6e001a94c852",
      "metadata": {},
      "source": [
        "# Elastic Net\n",
        "\n",
        "## Why Ordinary Least Squares (OLS) Fails\n",
        "OLS fails primarily due to **overfitting** in the presence of noise, **multicollinearity** (high correlation between predictors), and **lack of regularization**. Without regularization, OLS can produce large, unstable coefficients, especially when there are many predictors or high multicollinearity, leading to poor generalization on new data.\n",
        "\n",
        "## Ridge Regression (L2 Regularization)\n",
        "The cost function for Ridge regression is given by:\n",
        "\n",
        "$$\n",
        "J(\\beta) = \\|y - X\\beta\\|^2 + \\lambda \\|\\beta\\|^2\n",
        "$$\n",
        "\n",
        "The gradient of this cost function is:\n",
        "\n",
        "$$\n",
        "\\nabla J(\\beta) = -2X^T(y - X\\beta) + 2\\lambda \\beta\n",
        "$$\n",
        "\n",
        "- **Advantages**:\n",
        "  - Stabilizes the solution in the presence of multicollinearity.\n",
        "  - Provides a unique solution for $\\lambda > 0$.\n",
        "  - Helps prevent overfitting by shrinking the coefficients.\n",
        "\n",
        "- **Disadvantages**:\n",
        "  - Does not perform feature selection.\n",
        "  - Can introduce bias if $\\lambda$ is too large.\n",
        "\n",
        "## Lasso Regression (L1 Regularization)\n",
        "The cost function for Lasso regression is:\n",
        "\n",
        "$$\n",
        "J(\\beta) = \\|y - X\\beta\\|^2 + \\lambda \\|\\beta\\|_1\n",
        "$$\n",
        "\n",
        "The gradient of this cost function is:\n",
        "\n",
        "$$\n",
        "\\nabla J(\\beta) = -2X^T(y - X\\beta) + \\lambda \\, \\text{sign}(\\beta)\n",
        "$$\n",
        "\n",
        "- **Advantages**:\n",
        "  - Automatically performs feature selection by setting some coefficients to zero.\n",
        "  - Improves interpretability by focusing on key features.\n",
        "\n",
        "- **Disadvantages**:\n",
        "  - Struggles with correlated features, often selecting only one from a correlated group.\n",
        "  - Can introduce bias, especially with small datasets or large $\\lambda$.\n",
        "\n",
        "## ElasticNet Regression\n",
        "The cost function for ElasticNet regression is:\n",
        "\n",
        "$$\n",
        "J(\\beta) = \\|y - X\\beta\\|^2 + \\lambda_1 \\|\\beta\\|_1 + \\lambda_2 \\|\\beta\\|^2\n",
        "$$\n",
        "\n",
        "The gradient of this cost function is:\n",
        "\n",
        "$$\n",
        "\\nabla J(\\beta) = -2X^T(y - X\\beta) + \\lambda_1 \\, \\text{sign}(\\beta) + 2\\lambda_2 \\beta\n",
        "$$\n",
        "\n",
        "- **Advantages**:\n",
        "  - Combines Lasso and Ridge regularization, performing both feature selection and coefficient shrinkage.\n",
        "  - Handles correlated predictors better by keeping them with smaller coefficients.\n",
        "  - Flexible in adjusting $\\lambda_1/\\lambda_2$ to resemble Lasso or Ridge.\n",
        "  \n",
        "- **Disadvantages**:\n",
        "  - Requires tuning two hyperparameters, $\\lambda_1$ and $\\lambda_2$.\n",
        "  - Computationally expensive due to additional penalty terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1410cc1-52a0-4f1d-b751-d67b6145ccd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, Lasso, ElasticNet\n",
        ")\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa7017ed-59b2-4c13-8548-ae32369171d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(47)\n",
        "plt.style.use('dark_background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dfd63e2c-7656-4823-b68b-36f2f2fcb048",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data preparation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 3\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, n_samples)\n\u001b[1;32m      4\u001b[0m x2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, n_samples)\n\u001b[1;32m      5\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m x1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m*\u001b[39m x2 \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, n_samples)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Data preparation\n",
        "n_samples = 500\n",
        "x1 = np.random.randint(1, 100, n_samples)\n",
        "x2 = np.random.randint(-50, 50, n_samples)\n",
        "x3 = 0.5 * x1 + 0.3 * x2 + np.random.randint(0, 10, n_samples)\n",
        "x4 = np.random.randint(200, 500, n_samples)\n",
        "y = 2 + 3*x1 - 5*x2 + 2 * x3 + 0.1 * x4 + np.random.normal(0, 500, n_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "76e54a06-31d2-4a13-8e85-551bf7d0ad06",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      2\u001b[0m     x1\u001b[38;5;241m=\u001b[39mx1, x2\u001b[38;5;241m=\u001b[39mx2, x3\u001b[38;5;241m=\u001b[39mx3, x4\u001b[38;5;241m=\u001b[39mx4, y\u001b[38;5;241m=\u001b[39my\n\u001b[1;32m      3\u001b[0m ))\n\u001b[1;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(dict(\n",
        "    x1=x1, x2=x2, x3=x3, x4=x4, y=y\n",
        "))\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82ce8384-4630-4366-8d74-b923cf830d99",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mpairplot(data)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 10), dpi=300)\n",
        "sns.pairplot(data)\n",
        "plt.show()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cab15cc0-dc3b-44ba-8379-8b2f784a6aa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop('y', axis=1), \n",
        "    data['y'], test_size=0.2, random_state=47\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3553eb94-7e8a-4cbf-8ca2-6f35fc8a2a81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Squared Error and Coefficient of Determination:\n",
            "OLS MSE: 11629.803270170243, R^2: 0.644123156676849\n",
            "Ridge MSE: 11629.78725468109, R^2: 0.6441236467575142\n",
            "Lasso MSE: 11629.55009148034, R^2: 0.6441309040506322\n",
            "ElasticNet MSE: 11629.358870596647, R^2: 0.6441367554896364\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    \"OLS\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(alpha=1),\n",
        "    \"Lasso\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "}\n",
        "\n",
        "# Fit the models and predict\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[model_name] = [mse, r2]\n",
        "    \n",
        "print(\"\\nMean Squared Error and Coefficient of Determination:\")\n",
        "for model_name, o in results.items():\n",
        "    print(f\"{model_name} MSE: {o[0]}, R^2: {o[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054f9524-5872-4aad-a39a-6faa00cb719a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "book",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
